# auto-evol-instruct
Automatic Instruction Evolution is an framework designed to automatically enhance the complexity of instructions used for LLM fine-tuning without human effort.

[한국어](./README.ko.md) | [English](./README.md)

## Keywords
- Method: Prompt to enhance the complexity of instructions
- Trajectory: Every stages of instruction evolved by the method

## Key Features
- Automatic instruction complexity enhancement without human effort
- Support for various types of data
- Flexible configuration for method optimization process

## Introduction
This repository contains developed version of an automated algorithm for augmenting Korean language data through instruction evolution(https://github.com/joonavel/evol-instruct), based on the Automatic Instruction Evolving technique from the following paper:

Automatic Instruction Evolving for Large Language Models
(https://arxiv.org/abs/2406.00770)

Previous version of the implementation has limited number of evolving methods so that, it was not suitable for certain types of data. ex) Mathmatical problems, Code generation, etc.

This implementation has been developed to solve this problem by adding automatic evolving method optimization.

## Installation
```
pip install -r requirements.txt
```

## Usage

### Setting Environment Variables
Before running the project, you need to set the following environment variables in your .env file:
```
DEEPSEEK_API_KEY=your_deepseek_api_key
MY_HF_TOKEN=your_huggingface_api_key
```

### Required Parameters
- ```data_path <hf_dataset_name>```: Path to the hf dataset. There should be "instruction" and "response" fields in the dataset.
- ```train_size <int>```: Size of data to join method optimization.
- ```dev_size <int>```: Size of data to join method validation.
- ```seed <int>```: Random seed for reproducibility.
- ```batch_size <int>```: Batch size for whole process.
- ```max_steps <int>```: Maximum number of steps for method optimization.
- ```loop <int>```: Whole generation of method evolving.(l in the paper)
- ```candidate_size <int>```: Number of optimizatied methods.(m in the paper)
- ```test_run <int>```: Test run or not. if test_run is 1, only 10 instructions will be evolved.
- ```save_path <str>```: Path to save the evolution result.

### Optional Parameters
- ```evol_llm_config <str>```: Configuration for the evolving LLM.
- ```optim_llm_config <str>```: Configuration for the optimizing LLM.

### Model
Currently, Deepseek R1 is the only state-of-the-art LLM that is offered by API under the MIT License(Commercial use is allowed).
This framework is currently using DeepSeek R1 model for evolving and optimizing.
(https://deepseeklicense.github.io/)
If you want to use other models, you can change the model in the code.

### Example Usage
```bash
sh main.sh
```
Below is inside the script
```bash
python main.py\
    --data-path joonavel/seed_for_evolving\
    --train-size 20\
    --dev-size 50\
    --seed 42\
    --batch-size 10\
    --max-step 3\
    --loop 3\
    --candidate-size 5\
    --test-run 0\
    --save-path evolution_result.json
```
This command will...
1. Load the "joonavel/seed_for_evolving" dataset from the hf dataset.
2. Get 20 samples from the dataset for method optimization.
3. Get 50 samples from the dataset for method validation.
4. Method optimization process will be repeated 3 times(Method will be evolved 3 times).
5. The size of each trajectory of instruction evolving will be 3(loop).
6. The optimized method will be selected from 5 methods(candidate_size).
7. The evolution result will be saved to the "evolution_result.json" file.

## Components
This framework is composed of 5 main components.
- Evolver: Evolve the instruction by the method.
- Analyzer: Analyze the trajectory of instruction evolving and provide feedback.
- Optimizer: Optimize the method by the feedback.
- Validator: Validate the method by the dev dataset.
- Generator: Generate the instruction by the optimized method.

## Output
The script saves the results in JSON format to the specified output file.

Find a 2K dataset generated by this framework in the following link:
(https://huggingface.co/datasets/joonavel/ko-auto-evol-instruct)

## Appendix

### Is This Framework useful?
To verify the usefulness of the data generated by this repository's algorithm, we fine-tuned the Unsloth/Phi-4-bnb-4bit model using the following three datasets and compared their performance:

1. LIMA dataset translated into Korean (https://huggingface.co/datasets/taeshahn/ko-lima)
2. Dataset generated by Evol-Instruct (https://huggingface.co/datasets/joonavel/ko-evol-instruct)
3. Dataset generated by this repository (Auto-Evol-Instruct) (https://huggingface.co/datasets/joonavel/ko-auto-evol-instruct)

The models were evaluated using the KMMLU dataset. The model fine-tuned with the dataset generated by this repository outperformed the model fine-tuned with the Korean LIMA dataset, and showed slightly lower performance compared to the model fine-tuned with the Evol-Instruct dataset.

base model: 0.468

with kolima (epoch8): 0.494 https://huggingface.co/joonavel/Phi-4-kolima-adapter

with koevol (epoch8): 0.499 https://huggingface.co/joonavel/Phi-4-koevol-adapter

with koautoevol (epoch8): 0.497 https://huggingface.co/joonavel/Phi-4-koautoevol-adapter

### Limitations
Compared to the Evol-Instruct method, the Auto-Evol-Instruct method has the following two advantages:
1. There is no need to manually create Evolving Prompts (Methods) for each data type.
2. The seed data retention rate is high.
- koevol: Average loss rate during Evolving: 6.48%, average loss rate during Responsing: 55%(1722 -> 922) (increases significantly as generation increases)
- koautoevol: Average loss rate during Evolving: 0~1%, average loss rate during Responsing: 3.5%(2117 -> 2042)

Despite these advantages, the model fine-tuned with the dataset generated by Auto-Evol-Instruct showed lower KMMLU evaluation scores than the one generated by Evol-Instruct. The possible reasons are as follows:
- The Evol-Instruct method used prompts that increased not only the complexity but also the diversity of instructions.
- In contrast, the Auto-Evol-Instruct method does not explicitly include a process to increase diversity, resulting in a lack of diversity in the final dataset.
-> The performance gap is likely due to insufficient diversity in the training dataset.

Other possible factors that may have negatively affected performance include:
1. Inappropriateness of the Method Optimization results
2. Degradation of instruction quality during the Evolving process
3. The LLM failing to generate appropriate responses to instructions

Additional experiments are needed to confirm whether these factors actually had a negative impact on fine-tuning performance.